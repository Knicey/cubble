---
title: "data_structure"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{data_structure}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  eval = FALSE
)
```

```{r setup}
library(xxx)
library(tsibble)
library(sf)
library(ozmaps)
```

# Motivation for a new data structure:

```{r}
climate <- climate_monthly %>% head(100)

# build a tsibble
climate_tsibble <- climate %>% 
  mutate(date = yearmonth(date)) %>% 
  as_tsibble(key = c(station, param), index = date)

# build an sf from tsibble (can also build from tibble)
climate_sf <- climate_tsibble %>% filter(!is.na(lat)) %>% 
  st_as_sf(coords = c("long", "lat"), crs = st_crs(ozmap_country))

# spatial join returns an tibble/ sf
a <- climate_sf %>% 
  st_join(ozmap_states, join = st_within)
class(a) 

# turning it to tsibble again loses the sf structure
b <- a %>% as_tsibble(index = date, key = c(station, param))

class(b)

# hence would be nice to have a data structure that houses both tsibble and sf (with additional operations)
```

# Existing and similar work:

## Data structure:

-   `spacetime` builds a spatiotemporal object based on `xts` and `sp` class for handling time and spatial dimension. Both classes have been superseded by modern data structure, namely, `tsibble` and `sf`, respectively.

    -   Spacetime: Spatio-Temporal Data in R

-   `stars` package defines the spatiotemporal data as an array and provides operations based on the array structure. This definition fits well with the satellite imagery from remote sensing, where pixels in the image corresponds to the cells in the array.

    -   <https://github.com/r-spatial/stars/>

    -   "Multidimensional Arrays for anlaysing geoscientific data"

    -   "Spatio-temporal change detection from multidimensional arrays: Detecting deforestation from MOBIS time series"

-   `cubelyr` implements a `tbl_cube` class for tidyverse operations on arrays.

    -   <https://github.com/hadley/cubelyr/blob/master/R/cube.R>

-   `sf` implements a flat data structure for handling different geometry types in spatial data and introduces a set of operations based on the geometrical relations.

    -   Simple Features for R: standardized support for spatial vector data

-   `tsibble` implements a data structure for temporal data through defining the `key` and `index` variable

    -   A new tidy data structure to support exploration and modeling of temporal data

## Data wrangling operations:

-   There are also array operations defined in the following paper: **select, scale, reduce, rearrange, and compute**.

    -   Spatio-temporal change detection from multidimensional arrays: Detecting deforestation from MOBIS time series"

-   The package is still in experimental and the operations supported includes **select, rename filter, mutate, arrange, group_by/ungroup, and summarise (no join).**

    -   `cubelyr`

## How my work differs:

-   fixed set of locations + interest in time domain

    -   While satellite imagery can record information on a continuous spatial domain, other spatial information are recorded at a fixed set of locations characterised by latitude, longitude, and other spatial metadata. Examples of this type of data includes climate measures from weather observation stations and river level data recorded by electronic gauges. Analysing this data requires less considerations on the geometry type and map projection while more on how measures in these fixed locations changes across the time domain and whether these changes are related for adjacent locations.

    -   characteristics:

        -   less focus on complex geometry structure (point geometry) and projection

        -   more focus on the time dimension

        -   can be regular or irregular grid

-   A flat data structure for saptiotemporal data built on top of `tibble` means the adoption of tidyverse workflow where the data type and inputs and outputs are predictable and hence operations can be concatenated on top of one another. This workflow enhances the reproducibility of data analysis.
