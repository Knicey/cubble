---
title: "vis"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{vis}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  eval = FALSE
)
```

```{r setup}
library(cubble)
library(tsibble)
library(lubridate)
library(ggplot2)
library(ggmap)
library(dplyr)
```

# Set up `cubble_df` object

```{r}
oz_climate_tsibble <- oz_climate %>% as_tsibble(index = date, key = station)
oz_global2 <- oz_climate_tsibble %>% global(station)
oz_zoom2 <- oz_global2 %>% zoom(data)
```


# Summary

- Rendering less than 100 stations for 1 year worth of daily data is still slow. Try to sampe a few stations to plot first but `brolgar::sample_n_keys()` doesn't work for grouped data. Either have my own sampling function or make changes on `brolgar`. 

- Some stations have block missing for `tmax`, can filter out those bad stations in the list-column form before plotting with the long form data (still a minor fix is needed).

- Glyph map needs both station-wise and time-wise information to make, so would be nice to have a `migrate` function that add station wise info to the long format.


# Plots

## Plot with list-column format

Can make a geographic map: :)

```{r}
aus_map <- get_map(location = bbox(station), source = "osm")
ggmap(aus_map) + geom_point(data = oz_global2, aes(x = long, y = lat))
```

## Plot with long format

### Precipitation

Time series plot seems slow to make for all 93 stations:  

```{r eval = FALSE}
oz_zoom2_2020 <- oz_zoom2 %>% filter(year(date) == 2020) 

oz_zoom2_2020 %>% 
  ggplot() + 
  geom_line(aes(x = date, y = prcp, group = station)) + 
  facet_wrap(vars(station)) + 
  theme_void()
```

try sample a couple station: try sample_n_keys from brolgar and find that it doesn't work with grouped data. See example: 

```{r}
# pedestrain is not grouped (doesn't have grouped_ts and grouped_df as class) and it works fine
set.seed(123)
ped_sample_good <- pedestrian %>% sample_n_keys(size = 2)

# group pedestrain by key add grouped_ts and grouped_df in the class attributes and sample_n_keys() doesn't work
ped_gf <- pedestrian %>% group_by_key()
class(ped_gf)
set.seed(123)
ped_sample_bad <- ped_gf %>% sample_n_keys(size = 2)
ped_sample_bad

```

### Max temperature

Try with `tmax` rather than `prcp`: 

```{r}
oz_zoom2_2020 <- oz_zoom2 %>% dplyr::filter(year(date) == 2020) 

oz_zoom2_2020 %>% 
  ggplot() + 
  geom_line(aes(x = date, y = tmax, group = station)) + 
  facet_wrap(vars(station)) + 
  theme_void()
```

There are block missing for some stations, would be good to have a function to summarise these before filtering

```{r}
oz_zoom2_tmax <- oz_global2 %>% 
  zoom(data) %>% 
  filter(year(date) == 2020) %>% 
  global(station) %>% # some work here needs to be done here to make sure after global the list-col is still tsibble
  mutate(tmax_missing = sum(data$tmax, na.rm = TRUE)) %>% 
  filter(tmax_missing != 0) %>% 
  zoom(data)
  

oz_zoom2_tmax %>% 
  ggplot() + 
  geom_line(aes(x = date, y = tmax, group = station)) + 
  facet_wrap(vars(station)) + 
  theme_void()
```

Can do more aggregation to reduce the noise


### Glyph map


```{r}
oz_zoom2_prep <- oz_zoom2 %>% 
  dplyr::filter(lubridate::year(date) == 2020) %>% 
  mutate(yday = lubridate::yday(date)) %>% 
  dplyr::left_join(station %>% dplyr::select(id, lat, long), by = c("station" = "id"))

library(GGally)
library(ggplot2)
library(ggmap)
gly <- oz_zoom2_prep %>% glyphs("long", "yday", "lat", "tmax", height = 1, width = 2)
aus_map <- get_map(location = bbox(station), source = "osm")

ggmap(aus_map) + 
  # ggplot(gly, aes(x = gx, y = gy,  group = gid)) +
  #add_ref_lines(gly,color = "grey90") +
  #add_ref_boxes(gly, color = "grey90") +
  geom_path(data = gly, aes(x = gx, y = gy, group = gid)) +
  theme_void()
```

